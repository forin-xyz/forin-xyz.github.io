Title: 《统计学习方法》读书笔记4-从逻辑回归模型到最大熵模型, 含python实现
Date: 2016-02-20 23:00
Category: 机器学习
Tags: 机器学习, 逻辑回归, logistic regression, LR, 最大熵模型, maximum entropy model
Summary: 最大熵模型和逻辑回归模型一样, 也属于对数线性模型, 他是最大熵原理在分类问题上的推广.

## 最大熵模型

### 最大熵原理

学习概率模型时, 在所有可能的概率(模型)分布中, 熵最大的模型是最好的模型.

### 最大熵模型的定义

特征函数$f(x, y)$关于经验分布$\widetilde{P}(X, Y)$的期望
$$E_{\widetilde{P}}(f) = \sum\limits_{x, y}\widetilde{P}(x, y)f(x, y)$$

特征函数关于模型$P(Y|X)$和经验分布$\widetilde{P}(X)$的期望
$$
E_{P}(f) = \sum\limits_{x, y}\widetilde{P}(x)P(y|x)f(x, y)
$$

如果模型能够获取足够多的信息, 那么就可以假设这两个期望值相等

**最大熵模型**
>假设满足所有约束条件的模型集合为
>$$
>\mathcal(C) = {P \in \mathcal(P) | E_{\widetilde{P}}(f_i) = E_{P}(f_i), i=1, 2, \cdots, m}
>$$
>定义在条件概率分布$P(Y|X)$上的条件熵为
>$$
>H(P) = -\sum\limits_{x, y}\sum\limits_{x, y}\widetilde{P}(x)P(y|x)P(y|x)
>$$
>则模型集合C中条件熵最大的模型就是最大熵模型, 式中的对数为自然对数

### 最大熵模型的学习

原始问题
$$
\begin{aligned}
min\limits_{P \in \mathcal(C)}&  & -H(P)\\
s.t.&  & \sum\limits_{x, y}{\widetilde{P}(x, y)f_i(x, y)} = \sum\limits_{x, y}{\widetilde{P}(x)P(y|x)f_i(x, y)}, i=1, 2, \cdots, n\\
    &  &\sum\limits_{y}P(y|x) = 1
\end{aligned}
$$
对偶问题是
$$
max\limits{w} min\limits_{P} L(P, w)
$$

求$L(P, w)$关于$P(y|x)$的偏导数, 并令企等于0, 可以得到
$$
P_w(y|x) = \frac{1}{Z(x)}{exp(w_{i}f_{i}(x, y))}
$$
其中$Z(x)$是规范化因子, 有
$$
Z_w(x) = \sum\limits_{y}{exp(w_{i}f_{i}(x, y))}
$$
于是对偶问题等价于下面的最优化问题
$$
min\limits_{w}{\sum\limits_{x}{\widetilde{P}(x)logZ_w(x)} - \sum\limits_{x, y}{\widetilde{P}(x, y)\sum\limits_{i=1}{n}w_if_i(x, y)}}
$$
## 中英文对照表

最大熵模型 maximum entropy model

特征函数 feature function


