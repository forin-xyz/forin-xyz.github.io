<!DOCTYPE html>
<html lang="cn">
<head>
        <meta charset="utf-8" />
        <title>《统计学习方法》读书笔记8-k近邻法及python实现</title>
        <link rel="stylesheet" href="http://forin-xyz.github.io/output/theme/css/main.css" />

        <!--[if IE]>
            <script src="https://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
</head>

<body id="index" class="home">
<a href="http://github.com/forin-xyz/">
<img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png" alt="Fork me on GitHub" />
</a>
        <header id="banner" class="body">
                <h1><a href="http://forin-xyz.github.io/output/">耕有田，读有书 </a></h1>
                <nav><ul>
                    <li class="active"><a href="http://forin-xyz.github.io/output/category/ji-qi-xue-xi.html">机器学习</a></li>
                    <li><a href="http://forin-xyz.github.io/output/category/python.html">Python</a></li>
                    <li><a href="http://forin-xyz.github.io/output/category/sui-bi.html">随笔</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="http://forin-xyz.github.io/output/2016/02/du-shu-bi-ji-8-kjin-lin-fa.html" rel="bookmark"
           title="Permalink to 《统计学习方法》读书笔记8-k近邻法及python实现">《统计学习方法》读书笔记8-k近邻法及python实现</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2016-02-28T23:00:00+08:00">
                发表于: 2016年02月28日 星期日
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="http://forin-xyz.github.io/output/author/forin-xyz.html">forin-xyz</a>
        </address>
<p>In <a href="http://forin-xyz.github.io/output/category/ji-qi-xue-xi.html">机器学习</a>.</p>
<p>tags: <a href="http://forin-xyz.github.io/output/tag/ji-qi-xue-xi.html">机器学习</a> <a href="http://forin-xyz.github.io/output/tag/kjin-lin-fa.html">k近邻法</a> <a href="http://forin-xyz.github.io/output/tag/k-nearest-neighbor-method.html">k-nearest neighbor method</a> <a href="http://forin-xyz.github.io/output/tag/k-nn.html">k-NN</a> <a href="http://forin-xyz.github.io/output/tag/kdshu.html">kd树</a> <a href="http://forin-xyz.github.io/output/tag/du-shu-bi-ji.html">读书笔记</a> </p>
</footer><!-- /.post-info -->      <h2>k近邻算法</h2>
<p><strong> k 近邻法 </strong></p>
<blockquote>
<p>输入: 训练数据集T, 其中特征空间<span class="math">\(\mathcal{X} \subseteq \boldsystem{R}^n\)</span>, 输出空间<span class="math">\(\mathcal{Y} \subseteq \{c_1, c_2, \cdots, c_K\}\)</span>.</p>
<p>待预测实例特征向量<span class="math">\(x\)</span> 以及参数k</p>
<p>输出: 实例<span class="math">\(x\)</span>所属的类<span class="math">\(y\)</span></p>
<p>(1) 在训练集T中找出与x最邻近的k个点构成几何<span class="math">\(N_k(x)\)</span></p>
<p>(2) 在集合<span class="math">\(N_k(x)\)</span>中根据多数表决决定x所属的类
<div class="math">$$
y = \arg \max \limits_{c_j}{ freq(y = c_j, (x_i, y_i) \in N_k(x))}
$$</div>
</p>
</blockquote>
<p>当k=1时, 称为最近邻算法，此时将训练数据集中与x最近邻的点的类作为x的类。</p>
<h3>k近邻算法的python实现</h3>
<p><a href="https://github.com/forin-xyz/statistical-learning-method/blob/master/k_nearest_neighbor.py" title="gihub">k近邻算法</a></p>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">kNN_train</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">yk</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="kp">argsort</span><span class="p">(((</span><span class="n">X</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="kp">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">k</span><span class="p">]</span>
    <span class="n">yunique</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">unique</span><span class="p">(</span><span class="n">yk</span><span class="p">)</span>
    <span class="n">yend</span> <span class="o">=</span> <span class="n">yunique</span><span class="p">[(</span><span class="n">yk</span> <span class="o">-</span> <span class="n">yunique</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="kp">newaxis</span><span class="p">])</span><span class="o">.</span><span class="kp">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="kp">argmax</span><span class="p">()]</span>
    <span class="k">return</span> <span class="n">yend</span>

<span class="k">def</span> <span class="nf">test_kNN_train</span><span class="p">():</span>
    <span class="n">X</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
    <span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span>
    <span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mf">4.5</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">]</span>
    <span class="n">ypredit</span> <span class="o">=</span> <span class="n">kNN_train</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ypredit</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&#39;test kNN_train sucessfully&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">&#39;test kNN_train failed!&#39;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">test_kNN_train</span><span class="p">()</span>
</pre></div>


<h2>k近邻模型</h2>
<h3>距离度量</h3>
<p><span class="math">\(L_p\)</span>距离　或者　Ｍinkowski距离:
</p>
<div class="math">$$
L_p(x_i, x_j) = (\sum\limits_{l=1}{n}{\abs{x_{i}^{l} - x_{j}^{l}}^p})^{\frac{1}{p}}
$$</div>
<p>
这里<span class="math">\(p \geq 1\)</span></p>
<p>欧式距离 Euclidean distance:
</p>
<div class="math">$$
L_2(x_i, x_j) = (\sum\limits_{l=1}{n}{\abs{x_{i}^{l} - x_{j}^{l}}^2})^{\frac{1}{2}}
$$</div>
<p>曼哈顿距离 Manhattan distance
</p>
<div class="math">$$
L_2(x_i, x_j) = \sum\limits_{l=1}{n}{\abs{x_{i}^{l} - x_{j}^{l}}}
$$</div>
<p>当<span class="math">\(p=\infty\)</span>时,
</p>
<div class="math">$$
L_{\infty}(x_i, x_j) = \max\limits_{l}{\abs{x_{i}^{l} - x_{j}^{l}}}
$$</div>
<h3>k的选择</h3>
<p>如果选择较小的k值,就相当于用较小的邻域中的训练实例进行预测,"学习"的近似误差(approximation error)会减小, 但缺点是"学习"的估计误差(estimation error)会增大,预测结果会对近邻的实例点敏感.
如果邻近的实例点恰巧是噪声,预测就会出错.
换句话说,k值的减小就意味着整体模型变得复杂,容易产生过拟合</p>
<p>如果选择较大的k值,就相当于用较大的邻域进行预测,其优点是可以减小学习的估计误差,但缺点是学习的近似误差会增大. 这时与实例脚癣的训练实例也会对预测起作用,使预测发生错误,k值的增大意味着整体的模型变得简单.</p>
<p>若k=N, 那么无论输入实例是什么, 它都会简单的预测它属于训练中最多的类.</p>
<h3>分类决策规则</h3>
<p>多数表决等价于风险函数为0-1损失函数的经验风险最小化</p>
<h2>k近邻法的实现:kd树</h2>
<p><strong>算法2 构造平衡kd树</strong></p>
<blockquote>
<p>输入: k维空间数据集T</p>
<p>输出: kd树</p>
<p>(1) 开始: 构造根节点,根节点对应于包含T的k维空间的超矩形区域</p>
<p>选择<span class="math">\(x^{(1)}\)</span>为坐标轴, 以T中所有实例点的<span class="math">\(x^{(1)}\)</span>坐标的中位数为切分点,将根结点对应的超矩形区域切分成两个子区域.切分是由通过切分点并与坐标轴<span class="math">\(x^{(1)}\)</span>垂直的超平面实现</p>
<p>由根结点生成深度为1的左右子结点:左子结点对应于<span class="math">\(x_{(1)}\)</span>坐标小于切分点的子区域,右子结点对应于<span class="math">\(x_{(1)}\)</span>坐标大于切分点的子区域, 并将落在切分超平面上的实例点保存在根节点中.</p>
<p>(2) 重复: 对深度为j的结点, 选择<span class="math">\(x^{(l)}\)</span>为切分的坐标轴, <span class="math">\(l = j \mod k + 1\)</span>.</p>
<p>(3) 直到两个子区域没有实例存在时停止,从而构成kd树区域的划分</p>
</blockquote>
<p>注意,这里的中位数在样本数量为偶数时,是取最中间的两个数较大的那个数</p>
<h3>kd树的搜索</h3>
<p><strong>算法3 用kd树的k近邻算法</strong></p>
<blockquote>
<p>输入: 已构造的kd树, 目标点<span class="math">\(x\)</span>, k值</p>
<p>输出: x的k近邻构成的集合</p>
<p>(1) 在kd树中找出包含目标点k的叶结点: 从根结点开始,递归的向下访问kd树. 若目标点x当前维的坐标小于切分点的坐标, 则移动至左子结点, 否则移动到右子结点, 直到子结点为叶结点为止</p>
<p>(2) 从结点向上回退, 直到相应的结点包含的实例点个数大于等于k, 从这些实例点中选取出离目标实例点最近的k个实例点为x的"k近邻"<span class="math">\(N_k(x)\)</span></p>
<p>(3) 继续递归的像父结点回退, 并对每个结点进行以下操作:</p>
<p>(a) 如果该结点保存的实例点含有比当前"k近邻"集合<span class="math">\(N_k(x)\)</span>中的点离目标点更近的实例点, 则将<span class="math">\(N_k{x}\)</span>中离目标点较远的点给替换成较近的点</p>
<p>(b) 接着检查该子结点的父结点对应的另一子节点对应的区域是否含有更近点,如果有,则向上面一样对<span class="math">\(N_k(x)\)</span>进行更新</p>
<p>(4) 当回退到根结点时,搜索结束. 最后的<span class="math">\(N_k(x)\)</span>即为所求的集合.</p>
</blockquote>
<p>如果实例点是随机分布的, 那么kd树搜索的平均计算复杂度为<span class="math">\(O(\log{N})\)</span>, kd树适合于训练实例数远大于空间维数时的k近邻搜索.</p>
<h3>使用kd树的k近邻算法的python实现</h3>
<h2>中英文对照表</h2>
<p>k近邻 k-nearest neighbor, k-NN
单元　cell
类标记　class label
距离　distance
欧式距离 Euclidean distance
近似误差 approximation error
估计误差 estimation error
kd树 kd tree
线性扫描 linear scan
划分 partition
中位树 median</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
    </div><!-- /.entry-content -->
    <div class="comments">
      <div class="ds-share flat" data-thread-key="《统计学习方法》读书笔记8-k近邻法及python实现-key" data-title="《统计学习方法》读书笔记8-k近邻法及python实现" data-url="http://forin-xyz.github.io/output/2016/02/du-shu-bi-ji-8-kjin-lin-fa.html">
    <div class="ds-share-inline">
      <ul  class="ds-share-icons-16">

        <li data-toggle="ds-share-icons-more"><a class="ds-more" href="javascript:void(0);">分享到：</a></li>
        <li><a class="ds-weibo" href="javascript:void(0);" data-service="weibo">微博</a></li>
        <li><a class="ds-qzone" href="javascript:void(0);" data-service="qzone">QQ空间</a></li>
        <li><a class="ds-qqt" href="javascript:void(0);" data-service="qqt">腾讯微博</a></li>
        <li><a class="ds-wechat" href="javascript:void(0);" data-service="wechat">微信</a></li>
      </ul>
      <div class="ds-share-icons-more">
      </div>
    </div>
 </div>

      <h3>评论:</h3>
      <!-- Duoshuo Comment BEGIN -->
      <div class="ds-thread" data-thread-key="《统计学习方法》读书笔记8-k近邻法及python实现-key" data-title="《统计学习方法》读书笔记8-k近邻法及python实现" data-url="http://forin-xyz.github.io/output/2016/02/du-shu-bi-ji-8-kjin-lin-fa.html"></div>
      <!-- 多说评论框 end -->
      <!-- 多说公共JS代码 start (一个网页只需插入一次) -->
      <script type="text/javascript">
  var duoshuoQuery = {short_name:"forin-xyz"};
(function() {
  var ds = document.createElement('script');
  ds.type = 'text/javascript';ds.async = true;
  ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
  ds.charset = 'UTF-8';
  (document.getElementsByTagName('head')[0]
   || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
      </script>
      <noscript>Please enable JavaScript to view the comments.</noscript>
<!-- Duoshuo Comment END -->

  </article>
</section>
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>links</h2>
                        <ul>
                            <li><a href="http://forin-xyz.github.io/tutorial.html">我的导航</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="http://weibo.com/u/1756830393">微博</a></li>
                            <li><a href="http://github.com/forin-xyz">github</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
        </footer><!-- /#contentinfo -->

</body>
</html>